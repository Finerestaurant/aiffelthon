{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186cd88f-4dfa-4f29-9602-1686a6ebb97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m dataset_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mmel_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded data : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m target \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# (48, 1876)\u001b[39;00m\n",
      "File \u001b[0;32m~/module/dataloader.py:40\u001b[0m, in \u001b[0;36mmel_dataset.__init__\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m listdir:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m i:\n\u001b[0;32m---> 40\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1876\u001b[39m:\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m: \n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:413\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode)\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py:731\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m version \u001b[38;5;241m=\u001b[39m read_magic(fp)\n\u001b[1;32m    730\u001b[0m _check_version(version)\n\u001b[0;32m--> 731\u001b[0m shape, fortran_order, dtype \u001b[38;5;241m=\u001b[39m \u001b[43m_read_array_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    733\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py:594\u001b[0m, in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# The header is a pretty-printed string representation of a literal\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# boundary. The keys are strings.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# Versions (2, 0) and (1, 0) could have been created by a Python 2\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# implementation before header filtering was implemented.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 594\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[43m_filter_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m     d \u001b[38;5;241m=\u001b[39m safe_eval(header)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py:555\u001b[0m, in \u001b[0;36m_filter_header\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    553\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    554\u001b[0m last_token_was_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokenize\u001b[38;5;241m.\u001b[39mgenerate_tokens(StringIO(s)\u001b[38;5;241m.\u001b[39mreadline):\n\u001b[1;32m    556\u001b[0m     token_type \u001b[38;5;241m=\u001b[39m token[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    557\u001b[0m     token_string \u001b[38;5;241m=\u001b[39m token[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.8/tokenize.py:525\u001b[0m, in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    522\u001b[0m     continued \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pos \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mmax\u001b[39m:\n\u001b[0;32m--> 525\u001b[0m     pseudomatch \u001b[38;5;241m=\u001b[39m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPseudoToken\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmatch(line, pos)\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pseudomatch:                                \u001b[38;5;66;03m# scan for tokens\u001b[39;00m\n\u001b[1;32m    527\u001b[0m         start, end \u001b[38;5;241m=\u001b[39m pseudomatch\u001b[38;5;241m.\u001b[39mspan(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/tokenize.py:99\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile\u001b[39m(expr):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUNICODE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/re.py:252\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/re.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    292\u001b[0m     flags \u001b[38;5;241m=\u001b[39m flags\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataloader import mel_dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from Conv2d_model import Conv2d_VAE\n",
    "from linear_evaluation import linear_evaluation\n",
    "\n",
    "import flax \n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    x_train = [x for x, _ in batch]\n",
    "    y_train = [y for _, y in batch]                  \n",
    "        \n",
    "    return np.array(x_train), np.array(y_train)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 16\n",
    "    lr = 0.0001\n",
    "    rng = jax.random.PRNGKey(303)\n",
    "    \n",
    "    print('\\n')\n",
    "    # ---Load dataset---\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset_dir = os.path.join(os.path.expanduser('~'),'dataset')\n",
    "    data = mel_dataset(dataset_dir)\n",
    "    print(f'Loaded data : {len(data)}\\n')\n",
    "    target = data[0][0] # (48, 1876)\n",
    "    target = jnp.expand_dims(target, axis = 0)\n",
    "    \n",
    "    dataset_size = len(data)\n",
    "    train_size = int(dataset_size * 0.8)\n",
    "    test_size = dataset_size - train_size\n",
    "    \n",
    "    train_dataset, test_dataset = random_split(data, [train_size, test_size])\n",
    "\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_batch)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/4), shuffle=True, num_workers=0, collate_fn=collate_batch)\n",
    "    \n",
    "    print(f'batch_size = {batch_size}')\n",
    "    print(f'learning rate = {lr}')\n",
    "    print(f'train_size = {train_size}')\n",
    "    print(f'test_size = {test_size}')\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(\"Initialize complete!!\\n\")\n",
    "    # ---train model---\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fca991-7d2b-4d6b-9595-9345d2045746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(model, x_shape, key, lr) -> train_state.TrainState:\n",
    "    params = model.init({'params': key}, jnp.ones(x_shape), key)\n",
    "    # Create the optimizer\n",
    "    optimizer = optax.adam(learning_rate=lr)\n",
    "    # Create a State\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        tx=optimizer,\n",
    "        params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce25000-422f-4018-94eb-7615824f927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def kl_divergence(mean, logvar):\n",
    "    return -0.5 * jnp.sum(1 + logvar - jnp.square(mean) - jnp.exp(logvar))\n",
    "\n",
    "@jax.vmap\n",
    "def binary_cross_entropy_with_logits(logits, labels):\n",
    "    logits = nn.log_sigmoid(logits)\n",
    "    return -jnp.sum(labels * logits + (1. - labels) * jnp.log(-jnp.expm1(logits)))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, x, z_rng):\n",
    "    \n",
    "    x = jnp.expand_dims(x, axis=-1)\n",
    "    \n",
    "    def loss_fn(params):\n",
    "        recon_x, mean, logvar = Conv2d_VAE().apply(params, x, z_rng)\n",
    "\n",
    "        mse_loss = ((recon_x - x)**2).mean()\n",
    "        kld_loss = kl_divergence(mean, logvar).mean()\n",
    "        loss = mse_loss + kld_loss\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    \n",
    "    return state.apply_gradients(grads=grads), loss\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, x, z_rng):\n",
    "    x = jnp.expand_dims(x, axis=-1)\n",
    "    recon_x, mean, logvar = Conv2d_VAE().apply(state.params, x, z_rng)\n",
    "    mse_loss = ((recon_x -x)**2).mean()\n",
    "    kld_loss = kl_divergence(mean, logvar).mean()\n",
    "    loss = mse_loss + kld_loss\n",
    "    \n",
    "    return recon_x, loss, mse_loss, kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb355489-e4dd-4975-967a-c3521a15226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model....\n"
     ]
    }
   ],
   "source": [
    "# ---initializing model---\n",
    "model = Conv2d_VAE()\n",
    "print(\"Initializing model....\")\n",
    "state = init_state(model, \n",
    "                   (1, 48, 1876, 1),\n",
    "                   rng, \n",
    "                   lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1bbec2c-2644-47b8-bcfe-834cecff7d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0460000038146973, test_loss : 1.0040000677108765\r"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "# checkpoint_dir = str(input('checkpoint dir : '))\n",
    "\n",
    "\n",
    "train_loss_mean = 0\n",
    "test_loss_mean = 0\n",
    "\n",
    "\n",
    "rng, key = jax.random.split(rng)\n",
    "\n",
    "# x = x + 100\n",
    "# test_x = test_x + 100\n",
    "\n",
    "state, train_loss = train_step(state, np.random.randn(1, 48, 1876), rng)           \n",
    "_, test_loss, mse_loss, kld_loss = eval_step(state, np.random.randn(1, 48, 1876), rng)\n",
    "\n",
    "recon_x, _, _, _ = eval_step(state, np.random.randn(1, 48, 1876), rng)\n",
    "train_loss_mean += train_loss\n",
    "test_loss_mean += test_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f' {round(train_loss, 3)}, test_loss : {round(test_loss, 3)}', end='\\r')\n",
    "\n",
    "\n",
    "# ---Linear evaluation--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e366fbe-5a8d-4ae4-8614-6bd26ba5527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@jax.jit\n",
    "def encoder_apply(data, rng):\n",
    "    latent_vector = Encoder(train=False).apply({'params':enc_params,'batch_stats':enc_batch_stats}, data, rng)\n",
    "    return latent_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "019b3ab1-de6a-4033-b8ed-da26b9866437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Conv2d_model import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "993bd519-a14c-42b4-8799-62b9d8d45721",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector = encoder_apply(np.expand_dims(data[0][0], axis=(0,-1)), rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaa5799a-4085-43d4-b04c-6dcd900ca42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47621cf0-fcc1-41a4-8aad-589c9bd38a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "169166cd-9f29-4d0d-8616-b46a66916620",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = [x for x, y in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd7db85c-c8c9-422f-8ec7-e5aa5410b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 33637974016 bytes == 0x7fd60a000 @  0x7faf7ca3a680 0x7faf7ca5b824 0x7faf20d14064 0x7faf20d147ff 0x7faf20d72fc5 0x7faf20d761ea 0x7faf20d766e7 0x7faf20e13925 0x5c6617 0x570b26 0x569dba 0x6902a7 0x6023c4 0x5c6730 0x56bacd 0x501488 0x56d4d6 0x501488 0x56d4d6 0x501488 0x505166 0x56bbfa 0x5f6cd6 0x56bacd 0x5f6cd6 0x56bbfa 0x569dba 0x5f6eb3 0x50bc2c 0x5f6082 0x56d2d5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_array = np.array(x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2df0245a-01fb-40b6-8692-dc8d4c58ce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▌                                                                                                                                                                 | 2552/93389 [03:04<1:49:19, 13.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sing \u001b[38;5;129;01min\u001b[39;00m tqdm(data):\n\u001b[1;32m      3\u001b[0m     rng, key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng)\n\u001b[0;32m----> 4\u001b[0m     latent_vector \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43msing\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     whole_latent\u001b[38;5;241m.\u001b[39mappend(latent_vector)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "whole_latent = []\n",
    "for sing in tqdm(data):\n",
    "    rng, key = jax.random.split(rng)\n",
    "    latent_vector = encoder_apply(np.expand_dims(sing[0], axis=(0,-1)), rng)\n",
    "    whole_latent.append(latent_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681417b-bbce-481e-82fc-7cfdce21ebc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe314e9-80f2-4c03-a31a-7c966d01a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = linear_init_state(linear_evaluation(), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d613f9e-86f1-4006-b42f-6e2937b5cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_params = state.params['params']['encoder']\n",
    "enc_batch_stats = state.params['batch_stats']['encoder']\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
