{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc3fefc-9775-4b8b-bb80-2dfe953b681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "from typing import Callable, Any, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a10b8150-de1a-48d6-ad79-ef3b75ab44a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        #0\n",
    "        x = nn.Conv(512, kernel_size=(1,1),  strides=[1,1], kernel_dilation=2, padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        # x = nn.max_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        #1\n",
    "        x = nn.Conv(512,kernel_size=(1,1), strides=[2,2], kernel_dilation=2, padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        # x = nn.max_pool(x, window_shape=(2,2), strides=(1,1))\n",
    "\n",
    "        #2\n",
    "        x = nn.Conv(256,kernel_size=(1,1), strides=[1,1], kernel_dilation=2, padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    " \n",
    "        #3\n",
    "        x = nn.Conv(128,kernel_size=(1,3), strides=[1,1], kernel_dilation=2, padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        #4\n",
    "        x = nn.Conv(64, kernel_size=(1,3), strides=[1,1], kernel_dilation=2, padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        #5\n",
    "        x = nn.Conv(32, kernel_size=(1, 1), kernel_dilation=2, strides=[1,1], padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        #6\n",
    "        x = nn.Conv(16, kernel_size=(1,3), kernel_dilation=2, strides=[1,1],padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        #7\n",
    "        x = nn.Conv(1,kernel_size=(1,3), strides=[1,1], kernel_dilation=2, padding='same')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "\n",
    "        \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        \n",
    "        mean_x = nn.Dense(20, name='fc3_mean')(x)\n",
    "        logvar_x = nn.Dense(20, name='fc3_logvar')(x)\n",
    "        \n",
    "        \n",
    "        return mean_x, logvar_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "804006a8-22fa-41bf-9564-cd9da157bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2cbedc5b-2d81-41ad-ab62-ed6afcf69ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a1c00c1b-e930-484a-abf7-07ac2ed14229",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(16, 48, 1876,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7dc01b14-4e3b-4634-80f9-71b59be9b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vari = enc.init(rng, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a2cda795-8210-4d84-9d1f-71a4d1d51f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Encoder Summary                                       </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path        </span>┃<span style=\"font-weight: bold\"> outputs                 </span>┃<span style=\"font-weight: bold\"> batch_stats        </span>┃<span style=\"font-weight: bold\"> params                       </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float64</span>[16,48,1876,1]   │                    │                              │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_0 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,48,1876,512] │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]           │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]  │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,512]  │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]           │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]  │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_2 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,256]  │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256]           │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256]  │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">512 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.0 KB)</span>       │ <span style=\"font-weight: bold\">512 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.0 KB)</span>                 │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_3 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,128]  │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]           │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]  │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 KB)</span>       │ <span style=\"font-weight: bold\">256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 KB)</span>                 │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_4 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,64]   │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]            │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]   │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]           │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(512 B)</span>        │ <span style=\"font-weight: bold\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(512 B)</span>                  │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_5 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,32]   │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]            │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]   │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]           │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(256 B)</span>         │ <span style=\"font-weight: bold\">64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(256 B)</span>                   │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_6 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,16]   │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]            │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]   │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]           │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(128 B)</span>         │ <span style=\"font-weight: bold\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(128 B)</span>                   │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_7 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,1]    │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]             │\n",
       "│             │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]            │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ <span style=\"font-weight: bold\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span>            │ <span style=\"font-weight: bold\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span>                      │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_0      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,48,1876,512] │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]           │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1,1,512]   │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_1      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,512]  │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]           │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1,512,512] │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">262,656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.1 MB)</span>             │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_2      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,256]  │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256]           │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1,512,256] │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">131,328 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(525.3 KB)</span>           │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_3      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,128]  │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]           │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,256,128] │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">98,432 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(393.7 KB)</span>            │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_4      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,64]   │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]            │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,128,64]  │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">24,640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(98.6 KB)</span>             │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_5      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,32]   │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]            │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1,64,32]   │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">2,080 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8.3 KB)</span>               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_6      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,16]   │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]            │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,32,16]   │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">1,552 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(6.2 KB)</span>               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_7      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,1]    │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]             │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,16,1]    │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(196 B)</span>                   │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ fc3_logvar  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,20]          │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[20]            │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[5628,20]     │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">112,580 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(450.3 KB)</span>           │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ fc3_mean    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,20]          │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[20]            │\n",
       "│             │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[5628,20]     │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ <span style=\"font-weight: bold\">112,580 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(450.3 KB)</span>           │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Encoder     │ - <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,20]        │                    │                              │\n",
       "│             │ - <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,20]        │                    │                              │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">                   Total </span>│<span style=\"font-weight: bold\"> 3,042 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(12.2 KB)</span><span style=\"font-weight: bold\">    </span>│<span style=\"font-weight: bold\"> 749,963 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.0 MB)</span><span style=\"font-weight: bold\">             </span>│\n",
       "└─────────────┴─────────────────────────┴────────────────────┴──────────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                             </span>\n",
       "<span style=\"font-weight: bold\">                             Total Parameters: 753,005 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.0 MB)</span><span style=\"font-weight: bold\">                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Encoder Summary                                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbatch_stats       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs      │ \u001b[2mfloat64\u001b[0m[16,48,1876,1]   │                    │                              │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_0 │ \u001b[2mfloat32\u001b[0m[16,48,1876,512] │ mean: \u001b[2mfloat32\u001b[0m[512] │ bias: \u001b[2mfloat32\u001b[0m[512]           │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[512]  │ scale: \u001b[2mfloat32\u001b[0m[512]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_1 │ \u001b[2mfloat32\u001b[0m[16,24,938,512]  │ mean: \u001b[2mfloat32\u001b[0m[512] │ bias: \u001b[2mfloat32\u001b[0m[512]           │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[512]  │ scale: \u001b[2mfloat32\u001b[0m[512]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_2 │ \u001b[2mfloat32\u001b[0m[16,24,938,256]  │ mean: \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]           │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[256]  │ scale: \u001b[2mfloat32\u001b[0m[256]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 KB)\u001b[0m       │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 KB)\u001b[0m                 │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_3 │ \u001b[2mfloat32\u001b[0m[16,24,938,128]  │ mean: \u001b[2mfloat32\u001b[0m[128] │ bias: \u001b[2mfloat32\u001b[0m[128]           │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[128]  │ scale: \u001b[2mfloat32\u001b[0m[128]          │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m       │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m                 │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_4 │ \u001b[2mfloat32\u001b[0m[16,24,938,64]   │ mean: \u001b[2mfloat32\u001b[0m[64]  │ bias: \u001b[2mfloat32\u001b[0m[64]            │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[64]   │ scale: \u001b[2mfloat32\u001b[0m[64]           │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m        │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m                  │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_5 │ \u001b[2mfloat32\u001b[0m[16,12,469,32]   │ mean: \u001b[2mfloat32\u001b[0m[32]  │ bias: \u001b[2mfloat32\u001b[0m[32]            │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[32]   │ scale: \u001b[2mfloat32\u001b[0m[32]           │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m         │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m                   │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_6 │ \u001b[2mfloat32\u001b[0m[16,12,469,16]   │ mean: \u001b[2mfloat32\u001b[0m[16]  │ bias: \u001b[2mfloat32\u001b[0m[16]            │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[16]   │ scale: \u001b[2mfloat32\u001b[0m[16]           │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m32 \u001b[0m\u001b[1;2m(128 B)\u001b[0m         │ \u001b[1m32 \u001b[0m\u001b[1;2m(128 B)\u001b[0m                   │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ BatchNorm_7 │ \u001b[2mfloat32\u001b[0m[16,12,469,1]    │ mean: \u001b[2mfloat32\u001b[0m[1]   │ bias: \u001b[2mfloat32\u001b[0m[1]             │\n",
       "│             │                         │ var: \u001b[2mfloat32\u001b[0m[1]    │ scale: \u001b[2mfloat32\u001b[0m[1]            │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │ \u001b[1m2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m            │ \u001b[1m2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m                      │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_0      │ \u001b[2mfloat32\u001b[0m[16,48,1876,512] │                    │ bias: \u001b[2mfloat32\u001b[0m[512]           │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,1,1,512]   │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_1      │ \u001b[2mfloat32\u001b[0m[16,24,938,512]  │                    │ bias: \u001b[2mfloat32\u001b[0m[512]           │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,1,512,512] │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m262,656 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m             │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_2      │ \u001b[2mfloat32\u001b[0m[16,24,938,256]  │                    │ bias: \u001b[2mfloat32\u001b[0m[256]           │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,1,512,256] │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m131,328 \u001b[0m\u001b[1;2m(525.3 KB)\u001b[0m           │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_3      │ \u001b[2mfloat32\u001b[0m[16,24,938,128]  │                    │ bias: \u001b[2mfloat32\u001b[0m[128]           │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,3,256,128] │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m98,432 \u001b[0m\u001b[1;2m(393.7 KB)\u001b[0m            │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_4      │ \u001b[2mfloat32\u001b[0m[16,24,938,64]   │                    │ bias: \u001b[2mfloat32\u001b[0m[64]            │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,3,128,64]  │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m24,640 \u001b[0m\u001b[1;2m(98.6 KB)\u001b[0m             │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_5      │ \u001b[2mfloat32\u001b[0m[16,12,469,32]   │                    │ bias: \u001b[2mfloat32\u001b[0m[32]            │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,1,64,32]   │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m2,080 \u001b[0m\u001b[1;2m(8.3 KB)\u001b[0m               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_6      │ \u001b[2mfloat32\u001b[0m[16,12,469,16]   │                    │ bias: \u001b[2mfloat32\u001b[0m[16]            │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,3,32,16]   │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m1,552 \u001b[0m\u001b[1;2m(6.2 KB)\u001b[0m               │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Conv_7      │ \u001b[2mfloat32\u001b[0m[16,12,469,1]    │                    │ bias: \u001b[2mfloat32\u001b[0m[1]             │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[1,3,16,1]    │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m49 \u001b[0m\u001b[1;2m(196 B)\u001b[0m                   │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ fc3_logvar  │ \u001b[2mfloat32\u001b[0m[16,20]          │                    │ bias: \u001b[2mfloat32\u001b[0m[20]            │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[5628,20]     │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m112,580 \u001b[0m\u001b[1;2m(450.3 KB)\u001b[0m           │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ fc3_mean    │ \u001b[2mfloat32\u001b[0m[16,20]          │                    │ bias: \u001b[2mfloat32\u001b[0m[20]            │\n",
       "│             │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[5628,20]     │\n",
       "│             │                         │                    │                              │\n",
       "│             │                         │                    │ \u001b[1m112,580 \u001b[0m\u001b[1;2m(450.3 KB)\u001b[0m           │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│ Encoder     │ - \u001b[2mfloat32\u001b[0m[16,20]        │                    │                              │\n",
       "│             │ - \u001b[2mfloat32\u001b[0m[16,20]        │                    │                              │\n",
       "├─────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                  Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m3,042 \u001b[0m\u001b[1;2m(12.2 KB)\u001b[0m\u001b[1m   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m749,963 \u001b[0m\u001b[1;2m(3.0 MB)\u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────┴─────────────────────────┴────────────────────┴──────────────────────────────┘\n",
       "\u001b[1m                                                                                             \u001b[0m\n",
       "\u001b[1m                             Total Parameters: 753,005 \u001b[0m\u001b[1;2m(3.0 MB)\u001b[0m\u001b[1m                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_vari = enc.init(rng, x)\n",
    "nn.tabulate(enc, rngs={'params': rng})(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0d9c5d00-c85f-4b69-b38a-0fe90c6c79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(16,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b817caca-b30d-4c82-a854-426c29118c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        x = nn.Dense(12 * 469 * 1)(x)        \n",
    "        x = x.reshape(x.shape[0], 12, 469, 1)\n",
    "        \n",
    "    \n",
    "        #0\n",
    "        \n",
    "        x = nn.ConvTranspose(32, kernel_size=(1,3), strides=[1,1], kernel_dilation=(2,1))(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        #1\n",
    "        \n",
    "        x = nn.ConvTranspose(64, kernel_size=(1,3), strides=[1,1], kernel_dilation=(2,1))(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)        \n",
    "        \n",
    "        #2\n",
    "        \n",
    "        x = nn.ConvTranspose(128, kernel_size=(1,3), strides=[2,2], kernel_dilation=(2,1))(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        #3\n",
    "        \n",
    "        x = nn.ConvTranspose(256, kernel_size=(1,3), strides=[2,2], kernel_dilation=(2,1))(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        \n",
    "        #4\n",
    "        \n",
    "        x = nn.ConvTranspose(1, kernel_size=(1,3), strides=[1,1], kernel_dilation=(2,1))(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "54326275-d528-4cec-b309-d8c34f840453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c6fd3655-4c1f-454f-9697-321ec673cf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Decoder Summary                                       </span>\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path            </span>┃<span style=\"font-weight: bold\"> outputs                 </span>┃<span style=\"font-weight: bold\"> batch_stats        </span>┃<span style=\"font-weight: bold\"> params                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float64</span>[16,20]          │                    │                          │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ BatchNorm_0     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,32]   │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]        │\n",
       "│                 │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]   │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │ <span style=\"font-weight: bold\">64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(256 B)</span>         │ <span style=\"font-weight: bold\">64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(256 B)</span>               │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ BatchNorm_1     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,64]   │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]        │\n",
       "│                 │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]   │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │ <span style=\"font-weight: bold\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(512 B)</span>        │ <span style=\"font-weight: bold\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(512 B)</span>              │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ BatchNorm_2     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,128]  │ mean: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]       │\n",
       "│                 │                         │ var: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]  │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]      │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │ <span style=\"font-weight: bold\">256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 KB)</span>       │ <span style=\"font-weight: bold\">256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 KB)</span>             │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_0 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,32]   │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]        │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,1,32]        │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ <span style=\"font-weight: bold\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(512 B)</span>              │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,12,469,64]   │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]        │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,32,64]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ <span style=\"font-weight: bold\">6,208 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(24.8 KB)</span>          │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_2 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,24,938,128]  │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[128]       │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,64,128]      │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ <span style=\"font-weight: bold\">24,704 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(98.8 KB)</span>         │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_3 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,48,1876,256] │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256]       │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,128,256]     │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ <span style=\"font-weight: bold\">98,560 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(394.2 KB)</span>        │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_4 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,48,1876,1]   │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]         │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,3,256,1]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ <span style=\"font-weight: bold\">769 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.1 KB)</span>             │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ Dense_0         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,5628]        │                    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[5628]      │\n",
       "│                 │                         │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[20,5628] │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ <span style=\"font-weight: bold\">118,188 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(472.8 KB)</span>       │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ Decoder         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16,48,1876,1]   │                    │                          │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">                 </span>│<span style=\"font-weight: bold\">                   Total </span>│<span style=\"font-weight: bold\"> 448 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.8 KB)</span><span style=\"font-weight: bold\">       </span>│<span style=\"font-weight: bold\"> 249,005 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(996.0 KB)</span><span style=\"font-weight: bold\">       </span>│\n",
       "└─────────────────┴─────────────────────────┴────────────────────┴──────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                             </span>\n",
       "<span style=\"font-weight: bold\">                            Total Parameters: 249,453 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(997.8 KB)</span><span style=\"font-weight: bold\">                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Decoder Summary                                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbatch_stats       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs          │ \u001b[2mfloat64\u001b[0m[16,20]          │                    │                          │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ BatchNorm_0     │ \u001b[2mfloat32\u001b[0m[16,12,469,32]   │ mean: \u001b[2mfloat32\u001b[0m[32]  │ bias: \u001b[2mfloat32\u001b[0m[32]        │\n",
       "│                 │                         │ var: \u001b[2mfloat32\u001b[0m[32]   │ scale: \u001b[2mfloat32\u001b[0m[32]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m         │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m               │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ BatchNorm_1     │ \u001b[2mfloat32\u001b[0m[16,12,469,64]   │ mean: \u001b[2mfloat32\u001b[0m[64]  │ bias: \u001b[2mfloat32\u001b[0m[64]        │\n",
       "│                 │                         │ var: \u001b[2mfloat32\u001b[0m[64]   │ scale: \u001b[2mfloat32\u001b[0m[64]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m        │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m              │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ BatchNorm_2     │ \u001b[2mfloat32\u001b[0m[16,24,938,128]  │ mean: \u001b[2mfloat32\u001b[0m[128] │ bias: \u001b[2mfloat32\u001b[0m[128]       │\n",
       "│                 │                         │ var: \u001b[2mfloat32\u001b[0m[128]  │ scale: \u001b[2mfloat32\u001b[0m[128]      │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m       │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m             │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_0 │ \u001b[2mfloat32\u001b[0m[16,12,469,32]   │                    │ bias: \u001b[2mfloat32\u001b[0m[32]        │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ \u001b[2mfloat32\u001b[0m[1,3,1,32]        │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m              │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_1 │ \u001b[2mfloat32\u001b[0m[16,12,469,64]   │                    │ bias: \u001b[2mfloat32\u001b[0m[64]        │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ \u001b[2mfloat32\u001b[0m[1,3,32,64]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ \u001b[1m6,208 \u001b[0m\u001b[1;2m(24.8 KB)\u001b[0m          │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_2 │ \u001b[2mfloat32\u001b[0m[16,24,938,128]  │                    │ bias: \u001b[2mfloat32\u001b[0m[128]       │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ \u001b[2mfloat32\u001b[0m[1,3,64,128]      │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ \u001b[1m24,704 \u001b[0m\u001b[1;2m(98.8 KB)\u001b[0m         │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_3 │ \u001b[2mfloat32\u001b[0m[16,48,1876,256] │                    │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ \u001b[2mfloat32\u001b[0m[1,3,128,256]     │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ \u001b[1m98,560 \u001b[0m\u001b[1;2m(394.2 KB)\u001b[0m        │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ ConvTranspose_4 │ \u001b[2mfloat32\u001b[0m[16,48,1876,1]   │                    │ bias: \u001b[2mfloat32\u001b[0m[1]         │\n",
       "│                 │                         │                    │ kernel:                  │\n",
       "│                 │                         │                    │ \u001b[2mfloat32\u001b[0m[1,3,256,1]       │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ \u001b[1m769 \u001b[0m\u001b[1;2m(3.1 KB)\u001b[0m             │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ Dense_0         │ \u001b[2mfloat32\u001b[0m[16,5628]        │                    │ bias: \u001b[2mfloat32\u001b[0m[5628]      │\n",
       "│                 │                         │                    │ kernel: \u001b[2mfloat32\u001b[0m[20,5628] │\n",
       "│                 │                         │                    │                          │\n",
       "│                 │                         │                    │ \u001b[1m118,188 \u001b[0m\u001b[1;2m(472.8 KB)\u001b[0m       │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│ Decoder         │ \u001b[2mfloat32\u001b[0m[16,48,1876,1]   │                    │                          │\n",
       "├─────────────────┼─────────────────────────┼────────────────────┼──────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m               \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                  Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m448 \u001b[0m\u001b[1;2m(1.8 KB)\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m249,005 \u001b[0m\u001b[1;2m(996.0 KB)\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────────┴─────────────────────────┴────────────────────┴──────────────────────────┘\n",
       "\u001b[1m                                                                                             \u001b[0m\n",
       "\u001b[1m                            Total Parameters: 249,453 \u001b[0m\u001b[1;2m(997.8 KB)\u001b[0m\u001b[1m                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_vari = dec.init(rng, x = x)\n",
    "nn.tabulate(dec, rngs={'params': rng})(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb32ea6-6be1-4af8-835b-90f6bd1cdccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd82fa-1c15-4d96-a699-bb555daff722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
