
Loading dataset...
Loaded data : 6094
batch_size = 16
learning rate = 0.0001
train_size = 4875
test_size = 1219
Data load complete!
Initializing model....
Initialize complete!!
Epoch 1




























































epoch 1 - average loss - train : 7387.74658203125, test : 1615.201049804687555
Epoch 2


























































epoch 2 - average loss - train : 669.9020385742188, test : 665.1540527343752195
Epoch 3










































step : 215/305, train_loss : 374.5150146484375, test_loss : 321.858001708984444
Traceback (most recent call last):
  File "Dilated_conv_vae_main.py", line 147, in <module>
    x, y = next(train_data)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py", line 290, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/anthonypark6904/module/dataloader.py", line 69, in __getitem__
    self.x = np.load(self.file_list[index])
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py", line 413, in load
    return format.read_array(fid, allow_pickle=allow_pickle,
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 755, in read_array
    array = numpy.fromfile(fp, dtype=dtype, count=count)
KeyboardInterrupt
Traceback (most recent call last):
  File "Dilated_conv_vae_main.py", line 147, in <module>
    x, y = next(train_data)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py", line 290, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/anthonypark6904/module/dataloader.py", line 69, in __getitem__
    self.x = np.load(self.file_list[index])
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py", line 413, in load
    return format.read_array(fid, allow_pickle=allow_pickle,
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 755, in read_array
    array = numpy.fromfile(fp, dtype=dtype, count=count)

step : 216/305, train_loss : 413.6410217285156, test_loss : 383.224029541015644