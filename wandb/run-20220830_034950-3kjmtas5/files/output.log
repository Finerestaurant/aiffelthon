
Loading dataset...
Loaded data : 62235
batch_size = 128
learning rate = 0.0001
train_size = 49788
test_size = 12447
Data load complete!
Initializing model....
Initialize complete!!
Epoch 1
step : 5/389, train_loss : 81420.6171875, test_loss : 78187.6875755
CVAE_main.py:154: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument "figsize" which is no longer supported as of 3.3 and will become an error in 3.6
  plt.savefig('recon.png', figsize=(16, 16))
CVAE_main.py:157: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument "figsize" which is no longer supported as of 3.3 and will become an error in 3.6

























epoch 1 - average loss - train : 48188.390625, test : 48315.17187525555
Epoch 2
























epoch 2 - average loss - train : 43845.3125, test : 44110.5625.58593755
Epoch 3

























epoch 3 - average loss - train : 43594.84375, test : 43876.195312587525
Epoch 4

























epoch 4 - average loss - train : 43555.90234375, test : 43845.917968755
Epoch 5

























epoch 5 - average loss - train : 43293.0234375, test : 43602.7617187555
Epoch 6



















step : 294/389, train_loss : nan, test_loss : nanoss : 41591.289062525
Traceback (most recent call last):
  File "CVAE_main.py", line 138, in <module>
    test_x, test_y = next(test_data)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py", line 311, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/anthonypark6904/module/dataloader.py", line 69, in __getitem__
    self.x = np.load(self.file_list[index])
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py", line 430, in load
    return format.read_array(fid, allow_pickle=allow_pickle,
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 732, in read_array
    shape, fortran_order, dtype = _read_array_header(fp, version)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 595, in _read_array_header
    header = _filter_header(header)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 556, in _filter_header
    for token in tokenize.generate_tokens(StringIO(s).readline):
  File "/usr/lib/python3.8/tokenize.py", line 598, in _tokenize
    yield TokenInfo(OP, token, spos, epos, line)
  File "<string>", line 1, in __new__
KeyboardInterrupt
Traceback (most recent call last):
  File "CVAE_main.py", line 138, in <module>
    test_x, test_y = next(test_data)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py", line 311, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/anthonypark6904/module/dataloader.py", line 69, in __getitem__
    self.x = np.load(self.file_list[index])
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py", line 430, in load
    return format.read_array(fid, allow_pickle=allow_pickle,
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 732, in read_array
    shape, fortran_order, dtype = _read_array_header(fp, version)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 595, in _read_array_header
    header = _filter_header(header)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 556, in _filter_header
    for token in tokenize.generate_tokens(StringIO(s).readline):
  File "/usr/lib/python3.8/tokenize.py", line 598, in _tokenize
    yield TokenInfo(OP, token, spos, epos, line)
  File "<string>", line 1, in __new__
KeyboardInterrupt