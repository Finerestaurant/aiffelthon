
Loading dataset...
batch_size = 16
learning rate = 0.0001
train_size = 65372
validation_size = 18677
test_size = 9340
Data load complete!
Initializing model....
Initialize complete!!
[3m                                      SampleCNN Summary                                      
┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m path         [22m┃[1m outputs                [22m┃[1m batch_stats        [22m┃[1m params                       [22m┃
┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Inputs       │ float32[16,48,1876]    │                    │                              │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_0  │ float32[16,46,625,128] │ mean: float32[128] │ bias: float32[128]           │
│              │                        │ var: float32[128]  │ scale: float32[128]          │
│              │                        │                    │                              │
│              │                        │ [1m256 (1.0 KB)[22m       │ [1m256 (1.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_1  │ float32[16,44,312,128] │ mean: float32[128] │ bias: float32[128]           │
│              │                        │ var: float32[128]  │ scale: float32[128]          │
│              │                        │                    │                              │
│              │                        │ [1m256 (1.0 KB)[22m       │ [1m256 (1.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_10 │ float32[16,8,8,256]    │ mean: float32[256] │ bias: float32[256]           │
│              │                        │ var: float32[256]  │ scale: float32[256]          │
│              │                        │                    │                              │
│              │                        │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_2  │ float32[16,42,155,128] │ mean: float32[128] │ bias: float32[128]           │
│              │                        │ var: float32[128]  │ scale: float32[128]          │
│              │                        │                    │                              │
│              │                        │ [1m256 (1.0 KB)[22m       │ [1m256 (1.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_3  │ float32[16,40,77,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                        │ var: float32[256]  │ scale: float32[256]          │
│              │                        │                    │                              │
│              │                        │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_4  │ float32[16,38,38,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                        │ var: float32[256]  │ scale: float32[256]          │
│              │                        │                    │                              │
│              │                        │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_5  │ float32[16,18,18,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                        │ var: float32[256]  │ scale: float32[256]          │
│              │                        │                    │                              │
│              │                        │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_6  │ float32[16,16,16,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                        │ var: float32[256]  │ scale: float32[256]          │
│              │                        │                    │                              │
│              │                        │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_7  │ float32[16,14,14,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                        │ var: float32[256]  │ scale: float32[256]          │
│              │                        │                    │                              │
│              │                        │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_8  │ float32[16,12,12,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                        │ var: float32[256]  │ scale: float32[256]          │
│              │                        │                    │                              │
│              │                        │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_9  │ float32[16,10,10,512]  │ mean: float32[512] │ bias: float32[512]           │
│              │                        │ var: float32[512]  │ scale: float32[512]          │
│              │                        │                    │                              │
│              │                        │ [1m1,024 (4.1 KB)[22m     │ [1m1,024 (4.1 KB)[22m               │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_0       │ float32[16,46,625,128] │                    │ bias: float32[128]           │
│              │                        │                    │ kernel: float32[3,3,1,128]   │
│              │                        │                    │                              │
│              │                        │                    │ [1m1,280 (5.1 KB)[22m               │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_1       │ float32[16,44,312,128] │                    │ bias: float32[128]           │
│              │                        │                    │ kernel: float32[3,3,128,128] │
│              │                        │                    │                              │
│              │                        │                    │ [1m147,584 (590.3 KB)[22m           │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_10      │ float32[16,8,8,256]    │                    │ bias: float32[256]           │
│              │                        │                    │ kernel: float32[3,3,512,256] │
│              │                        │                    │                              │
│              │                        │                    │ [1m1,179,904 (4.7 MB)[22m           │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_2       │ float32[16,42,155,128] │                    │ bias: float32[128]           │
│              │                        │                    │ kernel: float32[3,3,128,128] │
│              │                        │                    │                              │
│              │                        │                    │ [1m147,584 (590.3 KB)[22m           │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_3       │ float32[16,40,77,256]  │                    │ bias: float32[256]           │
│              │                        │                    │ kernel: float32[3,3,128,256] │
│              │                        │                    │                              │
│              │                        │                    │ [1m295,168 (1.2 MB)[22m             │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_4       │ float32[16,38,38,256]  │                    │ bias: float32[256]           │
│              │                        │                    │ kernel: float32[3,3,256,256] │
│              │                        │                    │                              │
│              │                        │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_5       │ float32[16,18,18,256]  │                    │ bias: float32[256]           │
│              │                        │                    │ kernel: float32[3,3,256,256] │
│              │                        │                    │                              │
│              │                        │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_6       │ float32[16,16,16,256]  │                    │ bias: float32[256]           │
│              │                        │                    │ kernel: float32[3,3,256,256] │
│              │                        │                    │                              │
│              │                        │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_7       │ float32[16,14,14,256]  │                    │ bias: float32[256]           │
│              │                        │                    │ kernel: float32[3,3,256,256] │
│              │                        │                    │                              │
│              │                        │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_8       │ float32[16,12,12,256]  │                    │ bias: float32[256]           │
│              │                        │                    │ kernel: float32[3,3,256,256] │
│              │                        │                    │                              │
│              │                        │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_9       │ float32[16,10,10,512]  │                    │ bias: float32[512]           │
│              │                        │                    │ kernel: float32[3,3,256,512] │
│              │                        │                    │                              │
│              │                        │                    │ [1m1,180,160 (4.7 MB)[22m           │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Dense_0      │ float32[16,30]         │                    │ bias: float32[30]            │
│              │                        │                    │ kernel: float32[16384,30]    │
│              │                        │                    │                              │
│              │                        │                    │ [1m491,550 (2.0 MB)[22m             │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Dropout_0    │ float32[16,16,16,256]  │                    │                              │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ Dropout_1    │ float32[16,8,8,256]    │                    │                              │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│ SampleCNN    │ float32[16,30]         │                    │                              │
├──────────────┼────────────────────────┼────────────────────┼──────────────────────────────┤
│[1m              [22m│[1m                  Total [22m│[1m 5,376 (21.5 KB)    [22m│[1m 6,399,006 (25.6 MB)          [22m│
└──────────────┴────────────────────────┴────────────────────┴──────────────────────────────┘
[1m                                                                                             
[1m                            Total Parameters: 6,404,382 (25.6 MB)                            
Epoch 1












































step : 2960/4086, train loss : 3.331926107406616, train accuracy : 0.125, validation loss : 3.456926107406616, validation accuracy : 0.00505
Traceback (most recent call last):
  File "SampleCNN_main.py", line 144, in <module>
    x, y = next(train_data)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py", line 290, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/anthonypark6904/module/dataloader.py", line 69, in __getitem__
    self.x = np.load(self.file_list[index])
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py", line 413, in load
    return format.read_array(fid, allow_pickle=allow_pickle,
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 731, in read_array
    shape, fortran_order, dtype = _read_array_header(fp, version)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 596, in _read_array_header
    d = safe_eval(header)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/utils.py", line 1008, in safe_eval
    return ast.literal_eval(source)
  File "/usr/lib/python3.8/ast.py", line 59, in literal_eval
    node_or_string = parse(node_or_string, mode='eval')
  File "/usr/lib/python3.8/ast.py", line 47, in parse
    return compile(source, filename, mode, flags,
KeyboardInterrupt
Traceback (most recent call last):
  File "SampleCNN_main.py", line 144, in <module>
    x, y = next(train_data)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py", line 290, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/anthonypark6904/module/dataloader.py", line 69, in __getitem__
    self.x = np.load(self.file_list[index])
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py", line 413, in load
    return format.read_array(fid, allow_pickle=allow_pickle,
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 731, in read_array
    shape, fortran_order, dtype = _read_array_header(fp, version)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py", line 596, in _read_array_header
    d = safe_eval(header)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/utils.py", line 1008, in safe_eval
    return ast.literal_eval(source)
  File "/usr/lib/python3.8/ast.py", line 59, in literal_eval
    node_or_string = parse(node_or_string, mode='eval')
  File "/usr/lib/python3.8/ast.py", line 47, in parse
    return compile(source, filename, mode, flags,
KeyboardInterrupt