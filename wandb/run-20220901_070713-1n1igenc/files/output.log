
Loading dataset...
batch_size = 128
learning rate = 0.0001
train_size = 65372
validation_size = 18677
test_size = 9340
Data load complete!
Initializing model....
Initialize complete!!
[3m                                      SampleCNN Summary                                       
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m path         [22mâ”ƒ[1m outputs                 [22mâ”ƒ[1m batch_stats        [22mâ”ƒ[1m params                       [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Inputs       â”‚ float32[128,48,1876]    â”‚                    â”‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_0  â”‚ float32[128,46,625,128] â”‚ mean: float32[128] â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚ var: float32[128]  â”‚ scale: float32[128]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m256 (1.0 KB)[22m       â”‚ [1m256 (1.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_1  â”‚ float32[128,44,312,128] â”‚ mean: float32[128] â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚ var: float32[128]  â”‚ scale: float32[128]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m256 (1.0 KB)[22m       â”‚ [1m256 (1.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_10 â”‚ float32[128,6,95,64]    â”‚ mean: float32[64]  â”‚ bias: float32[64]            â”‚
â”‚              â”‚                         â”‚ var: float32[64]   â”‚ scale: float32[64]           â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m128 (512 B)[22m        â”‚ [1m128 (512 B)[22m                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_2  â”‚ float32[128,42,310,128] â”‚ mean: float32[128] â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚ var: float32[128]  â”‚ scale: float32[128]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m256 (1.0 KB)[22m       â”‚ [1m256 (1.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_3  â”‚ float32[128,12,101,256] â”‚ mean: float32[256] â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚ var: float32[256]  â”‚ scale: float32[256]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m512 (2.0 KB)[22m       â”‚ [1m512 (2.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_4  â”‚ float32[128,10,99,256]  â”‚ mean: float32[256] â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚ var: float32[256]  â”‚ scale: float32[256]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m512 (2.0 KB)[22m       â”‚ [1m512 (2.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_5  â”‚ float32[128,10,99,256]  â”‚ mean: float32[256] â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚ var: float32[256]  â”‚ scale: float32[256]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m512 (2.0 KB)[22m       â”‚ [1m512 (2.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_6  â”‚ float32[128,10,99,512]  â”‚ mean: float32[512] â”‚ bias: float32[512]           â”‚
â”‚              â”‚                         â”‚ var: float32[512]  â”‚ scale: float32[512]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m1,024 (4.1 KB)[22m     â”‚ [1m1,024 (4.1 KB)[22m               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_7  â”‚ float32[128,10,99,256]  â”‚ mean: float32[256] â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚ var: float32[256]  â”‚ scale: float32[256]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m512 (2.0 KB)[22m       â”‚ [1m512 (2.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_8  â”‚ float32[128,10,99,128]  â”‚ mean: float32[128] â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚ var: float32[128]  â”‚ scale: float32[128]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m256 (1.0 KB)[22m       â”‚ [1m256 (1.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BatchNorm_9  â”‚ float32[128,8,97,128]   â”‚ mean: float32[128] â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚ var: float32[128]  â”‚ scale: float32[128]          â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚ [1m256 (1.0 KB)[22m       â”‚ [1m256 (1.0 KB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_0       â”‚ float32[128,46,625,128] â”‚                    â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,1,128]   â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m1,280 (5.1 KB)[22m               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_1       â”‚ float32[128,44,312,128] â”‚                    â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,128,128] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m147,584 (590.3 KB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_10      â”‚ float32[128,6,95,64]    â”‚                    â”‚ bias: float32[64]            â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,128,64]  â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m73,792 (295.2 KB)[22m            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_2       â”‚ float32[128,42,310,128] â”‚                    â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,128,128] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m147,584 (590.3 KB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_3       â”‚ float32[128,12,101,256] â”‚                    â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,128,256] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m295,168 (1.2 MB)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_4       â”‚ float32[128,10,99,256]  â”‚                    â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,256,256] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m590,080 (2.4 MB)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_5       â”‚ float32[128,10,99,256]  â”‚                    â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,256,256] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m590,080 (2.4 MB)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_6       â”‚ float32[128,10,99,512]  â”‚                    â”‚ bias: float32[512]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,256,512] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m1,180,160 (4.7 MB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_7       â”‚ float32[128,10,99,256]  â”‚                    â”‚ bias: float32[256]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,512,256] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m1,179,904 (4.7 MB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_8       â”‚ float32[128,10,99,128]  â”‚                    â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,256,128] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m295,040 (1.2 MB)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv_9       â”‚ float32[128,8,97,128]   â”‚                    â”‚ bias: float32[128]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[3,3,128,128] â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m147,584 (590.3 KB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense_0      â”‚ float32[128,512]        â”‚                    â”‚ bias: float32[512]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[36480,512]   â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m18,678,272 (74.7 MB)[22m         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense_1      â”‚ float32[128,512]        â”‚                    â”‚ bias: float32[512]           â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[512,512]     â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m262,656 (1.1 MB)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense_2      â”‚ float32[128,30]         â”‚                    â”‚ bias: float32[30]            â”‚
â”‚              â”‚                         â”‚                    â”‚ kernel: float32[512,30]      â”‚
â”‚              â”‚                         â”‚                    â”‚                              â”‚
â”‚              â”‚                         â”‚                    â”‚ [1m15,390 (61.6 KB)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dropout_0    â”‚ float32[128,10,99,512]  â”‚                    â”‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dropout_1    â”‚ float32[128,6,95,64]    â”‚                    â”‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SampleCNN    â”‚ float32[128,30]         â”‚                    â”‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚[1m              [22mâ”‚[1m                   Total [22mâ”‚[1m 4,480 (17.9 KB)    [22mâ”‚[1m 23,609,054 (94.4 MB)         [22mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m                                                                                              
[1m                            Total Parameters: 23,613,534 (94.5 MB)                            
Epoch 1






































































epoch 1 - train average loss : 2.3999905586242676 - train accuracy : 0.28580400347709656 validation average loss : 2.3843016624450684, validation average accuracy : 0.2881604731082916
Epoch 2





































































epoch 2 - train average loss : 2.0077645778656006 - train accuracy : 0.41024699807167053 validation average loss : 2.0168440341949463, validation average accuracy : 0.40692269802093506
Epoch 3





































































epoch 3 - train average loss : 1.855749249458313 - train accuracy : 0.4516586363315582 validation average loss : 1.8943556547164917, validation average accuracy : 0.44202542304992676
Epoch 4





































































epoch 4 - train average loss : 1.7553856372833252 - train accuracy : 0.4782070219516754 validation average loss : 1.8412364721298218, validation average accuracy : 0.45768100023269653
Epoch 5






































































epoch 5 - train average loss : 1.6637752056121826 - train accuracy : 0.4994741976261139 validation average loss : 1.7900229692459106, validation average accuracy : 0.4710127115249634
Epoch 6






































































epoch 6 - train average loss : 1.5840561389923096 - train accuracy : 0.5220681428909302 validation average loss : 1.7775609493255615, validation average accuracy : 0.48024705052375793
Epoch 7





































































epoch 7 - train average loss : 1.495751142501831 - train accuracy : 0.5453707575798035 validation average loss : 1.789542555809021, validation average accuracy : 0.4796355068683624
Epoch 8





































































epoch 8 - train average loss : 1.3987966775894165 - train accuracy : 0.5694782733917236 validation average loss : 1.8088617324829102, validation average accuracy : 0.48049166798591614
Epoch 9





































































epoch 9 - train average loss : 1.298671007156372 - train accuracy : 0.5956856608390808 validation average loss : 1.8766244649887085, validation average accuracy : 0.46893346309661865
Epoch 10






































































epoch 10 - train average loss : 1.1964867115020752 - train accuracy : 0.6225338578224182 validation average loss : 1.9399360418319702, validation average accuracy : 0.469973087310791
Epoch 11





































































epoch 11 - train average loss : 1.0854213237762451 - train accuracy : 0.6526678204536438 validation average loss : 2.0440359115600586, validation average accuracy : 0.46263453364372253
Epoch 12







































step : 281/511, t_loss : 1.0277702808380127, t_accuracy : 0.6953125, v_loss : 2.096940040588379, v_accuracy : 0.562575
Traceback (most recent call last):
  File "SampleCNN_main.py", line 158, in <module>
    wandb.log({'train_loss' : train_loss,  'train_accuracy': train_accuracy, 'validation_loss' : validation_loss, 'validation_accuracy' : validation_accuracy})
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 289, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 255, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1591, in log
    self._log(data=data, step=step, commit=commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1375, in _log
    self._partial_history_callback(data, step, commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1259, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface.py", line 548, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 827, in json_dumps_safer_history
    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/usr/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 790, in default
    obj, converted = json_friendly(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 606, in json_friendly
    obj = get_jax_tensor(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 482, in get_jax_tensor
    return jax.device_get(obj)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2928, in device_get
    return tree_map(_device_get, x)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in tree_map
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in <genexpr>
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2889, in _device_get
    return toarray()
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/device_array.py", line 265, in __array__
    return np.asarray(self._value, dtype=dtype)
KeyboardInterrupt
Traceback (most recent call last):
  File "SampleCNN_main.py", line 158, in <module>
    wandb.log({'train_loss' : train_loss,  'train_accuracy': train_accuracy, 'validation_loss' : validation_loss, 'validation_accuracy' : validation_accuracy})
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 289, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 255, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1591, in log
    self._log(data=data, step=step, commit=commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1375, in _log
    self._partial_history_callback(data, step, commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1259, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface.py", line 548, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 827, in json_dumps_safer_history
    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/usr/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 790, in default
    obj, converted = json_friendly(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 606, in json_friendly
    obj = get_jax_tensor(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 482, in get_jax_tensor
    return jax.device_get(obj)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2928, in device_get
    return tree_map(_device_get, x)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in tree_map
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in <genexpr>
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2889, in _device_get
    return toarray()
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/device_array.py", line 265, in __array__
    return np.asarray(self._value, dtype=dtype)
KeyboardInterrupt