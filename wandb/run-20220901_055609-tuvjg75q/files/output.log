
Loading dataset...
batch_size = 128
learning rate = 0.0001
train_size = 65372
validation_size = 18677
test_size = 9340
Data load complete!
Initializing model....
Initialize complete!!
[3m                                      SampleCNN Summary                                       
┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m path         [22m┃[1m outputs                 [22m┃[1m batch_stats        [22m┃[1m params                       [22m┃
┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Inputs       │ float32[128,48,1876]    │                    │                              │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_0  │ float32[128,46,625,128] │ mean: float32[128] │ bias: float32[128]           │
│              │                         │ var: float32[128]  │ scale: float32[128]          │
│              │                         │                    │                              │
│              │                         │ [1m256 (1.0 KB)[22m       │ [1m256 (1.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_1  │ float32[128,44,312,128] │ mean: float32[128] │ bias: float32[128]           │
│              │                         │ var: float32[128]  │ scale: float32[128]          │
│              │                         │                    │                              │
│              │                         │ [1m256 (1.0 KB)[22m       │ [1m256 (1.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_10 │ float32[128,8,8,256]    │ mean: float32[256] │ bias: float32[256]           │
│              │                         │ var: float32[256]  │ scale: float32[256]          │
│              │                         │                    │                              │
│              │                         │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_2  │ float32[128,42,155,128] │ mean: float32[128] │ bias: float32[128]           │
│              │                         │ var: float32[128]  │ scale: float32[128]          │
│              │                         │                    │                              │
│              │                         │ [1m256 (1.0 KB)[22m       │ [1m256 (1.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_3  │ float32[128,40,77,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                         │ var: float32[256]  │ scale: float32[256]          │
│              │                         │                    │                              │
│              │                         │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_4  │ float32[128,38,38,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                         │ var: float32[256]  │ scale: float32[256]          │
│              │                         │                    │                              │
│              │                         │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_5  │ float32[128,18,18,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                         │ var: float32[256]  │ scale: float32[256]          │
│              │                         │                    │                              │
│              │                         │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_6  │ float32[128,16,16,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                         │ var: float32[256]  │ scale: float32[256]          │
│              │                         │                    │                              │
│              │                         │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_7  │ float32[128,14,14,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                         │ var: float32[256]  │ scale: float32[256]          │
│              │                         │                    │                              │
│              │                         │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_8  │ float32[128,12,12,256]  │ mean: float32[256] │ bias: float32[256]           │
│              │                         │ var: float32[256]  │ scale: float32[256]          │
│              │                         │                    │                              │
│              │                         │ [1m512 (2.0 KB)[22m       │ [1m512 (2.0 KB)[22m                 │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ BatchNorm_9  │ float32[128,10,10,512]  │ mean: float32[512] │ bias: float32[512]           │
│              │                         │ var: float32[512]  │ scale: float32[512]          │
│              │                         │                    │                              │
│              │                         │ [1m1,024 (4.1 KB)[22m     │ [1m1,024 (4.1 KB)[22m               │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_0       │ float32[128,46,625,128] │                    │ bias: float32[128]           │
│              │                         │                    │ kernel: float32[3,3,1,128]   │
│              │                         │                    │                              │
│              │                         │                    │ [1m1,280 (5.1 KB)[22m               │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_1       │ float32[128,44,312,128] │                    │ bias: float32[128]           │
│              │                         │                    │ kernel: float32[3,3,128,128] │
│              │                         │                    │                              │
│              │                         │                    │ [1m147,584 (590.3 KB)[22m           │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_10      │ float32[128,8,8,256]    │                    │ bias: float32[256]           │
│              │                         │                    │ kernel: float32[3,3,512,256] │
│              │                         │                    │                              │
│              │                         │                    │ [1m1,179,904 (4.7 MB)[22m           │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_2       │ float32[128,42,155,128] │                    │ bias: float32[128]           │
│              │                         │                    │ kernel: float32[3,3,128,128] │
│              │                         │                    │                              │
│              │                         │                    │ [1m147,584 (590.3 KB)[22m           │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_3       │ float32[128,40,77,256]  │                    │ bias: float32[256]           │
│              │                         │                    │ kernel: float32[3,3,128,256] │
│              │                         │                    │                              │
│              │                         │                    │ [1m295,168 (1.2 MB)[22m             │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_4       │ float32[128,38,38,256]  │                    │ bias: float32[256]           │
│              │                         │                    │ kernel: float32[3,3,256,256] │
│              │                         │                    │                              │
│              │                         │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_5       │ float32[128,18,18,256]  │                    │ bias: float32[256]           │
│              │                         │                    │ kernel: float32[3,3,256,256] │
│              │                         │                    │                              │
│              │                         │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_6       │ float32[128,16,16,256]  │                    │ bias: float32[256]           │
│              │                         │                    │ kernel: float32[3,3,256,256] │
│              │                         │                    │                              │
│              │                         │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_7       │ float32[128,14,14,256]  │                    │ bias: float32[256]           │
│              │                         │                    │ kernel: float32[3,3,256,256] │
│              │                         │                    │                              │
│              │                         │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_8       │ float32[128,12,12,256]  │                    │ bias: float32[256]           │
│              │                         │                    │ kernel: float32[3,3,256,256] │
│              │                         │                    │                              │
│              │                         │                    │ [1m590,080 (2.4 MB)[22m             │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Conv_9       │ float32[128,10,10,512]  │                    │ bias: float32[512]           │
│              │                         │                    │ kernel: float32[3,3,256,512] │
│              │                         │                    │                              │
│              │                         │                    │ [1m1,180,160 (4.7 MB)[22m           │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Dense_0      │ float32[128,30]         │                    │ bias: float32[30]            │
│              │                         │                    │ kernel: float32[16384,30]    │
│              │                         │                    │                              │
│              │                         │                    │ [1m491,550 (2.0 MB)[22m             │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Dropout_0    │ float32[128,16,16,256]  │                    │                              │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ Dropout_1    │ float32[128,8,8,256]    │                    │                              │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│ SampleCNN    │ float32[128,30]         │                    │                              │
├──────────────┼─────────────────────────┼────────────────────┼──────────────────────────────┤
│[1m              [22m│[1m                   Total [22m│[1m 5,376 (21.5 KB)    [22m│[1m 6,399,006 (25.6 MB)          [22m│
└──────────────┴─────────────────────────┴────────────────────┴──────────────────────────────┘
[1m                                                                                              
[1m                            Total Parameters: 6,404,382 (25.6 MB)                             
Epoch 1





















































epoch 1 - train average loss : 2.581411838531494 - train accuracy : 0.20960140228271484 validation average loss : 2.5984466075897217, validation average accuracy : 0.20627446472644806
Epoch 2






















































epoch 2 - train average loss : 2.271390676498413 - train accuracy : 0.3211420774459839 validation average loss : 2.290607213973999, validation average accuracy : 0.3136007785797119
Epoch 3






















































epoch 3 - train average loss : 2.1091468334198 - train accuracy : 0.37514621019363403 validation average loss : 2.141483783721924, validation average accuracy : 0.36252444982528687
Epoch 4






















































epoch 4 - train average loss : 1.9938162565231323 - train accuracy : 0.41019847989082336 validation average loss : 2.0237436294555664, validation average accuracy : 0.3992783725261688
Epoch 5





















































epoch 5 - train average loss : 1.901070237159729 - train accuracy : 0.4344615638256073 validation average loss : 1.9690920114517212, validation average accuracy : 0.41921478509902954
Epoch 6























































epoch 6 - train average loss : 1.8253644704818726 - train accuracy : 0.4575819671154022 validation average loss : 1.9232066869735718, validation average accuracy : 0.430772989988327
Epoch 7





















































epoch 7 - train average loss : 1.7527282238006592 - train accuracy : 0.47926658391952515 validation average loss : 1.9003510475158691, validation average accuracy : 0.43707191944122314
Epoch 8





















































epoch 8 - train average loss : 1.6621911525726318 - train accuracy : 0.5031116008758545 validation average loss : 1.8844329118728638, validation average accuracy : 0.44538894295692444
Epoch 9




















































epoch 9 - train average loss : 1.5560133457183838 - train accuracy : 0.5318276286125183 validation average loss : 1.9015244245529175, validation average accuracy : 0.4465508759021759
Epoch 10





















































epoch 10 - train average loss : 1.442873477935791 - train accuracy : 0.5613460540771484 validation average loss : 1.9837132692337036, validation average accuracy : 0.4406188726425171
Epoch 11





















































epoch 11 - train average loss : 1.313154697418213 - train accuracy : 0.5986636281013489 validation average loss : 2.107776165008545, validation average accuracy : 0.4256359934806824
Epoch 12





















































epoch 12 - train average loss : 1.1562856435775757 - train accuracy : 0.6444883942604065 validation average loss : 2.2473831176757812, validation average accuracy : 0.42502444982528687
Epoch 13





















































epoch 13 - train average loss : 1.0096474885940552 - train accuracy : 0.6870938539505005 validation average loss : 2.4613683223724365, validation average accuracy : 0.4159124195575714
Epoch 14













step : 125/511, t_loss : 0.8078789710998535, t_accuracy : 0.71875, v_loss : 2.9196722507476807, v_accuracy : 0.2537555
Traceback (most recent call last):
  File "SampleCNN_main.py", line 158, in <module>
    wandb.log({'train_loss' : train_loss,  'train_accuracy': train_accuracy, 'validation_loss' : validation_loss, 'validation_accuracy' : validation_accuracy})
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 289, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 255, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1591, in log
    self._log(data=data, step=step, commit=commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1375, in _log
    self._partial_history_callback(data, step, commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1259, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface.py", line 548, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 827, in json_dumps_safer_history
    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/usr/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 790, in default
    obj, converted = json_friendly(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 606, in json_friendly
    obj = get_jax_tensor(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 482, in get_jax_tensor
    return jax.device_get(obj)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2928, in device_get
    return tree_map(_device_get, x)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in tree_map
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in <genexpr>
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2889, in _device_get
    return toarray()
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/device_array.py", line 265, in __array__
    return np.asarray(self._value, dtype=dtype)
KeyboardInterrupt
Traceback (most recent call last):
  File "SampleCNN_main.py", line 158, in <module>
    wandb.log({'train_loss' : train_loss,  'train_accuracy': train_accuracy, 'validation_loss' : validation_loss, 'validation_accuracy' : validation_accuracy})
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 289, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 255, in wrapper
    return func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1591, in log
    self._log(data=data, step=step, commit=commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1375, in _log
    self._partial_history_callback(data, step, commit)
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py", line 1259, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface.py", line 548, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 827, in json_dumps_safer_history
    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/usr/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 790, in default
    obj, converted = json_friendly(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 606, in json_friendly
    obj = get_jax_tensor(obj)
  File "/usr/local/lib/python3.8/dist-packages/wandb/util.py", line 482, in get_jax_tensor
    return jax.device_get(obj)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2928, in device_get
    return tree_map(_device_get, x)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in tree_map
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/tree_util.py", line 205, in <genexpr>
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2889, in _device_get
    return toarray()
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/device_array.py", line 265, in __array__
    return np.asarray(self._value, dtype=dtype)
KeyboardInterrupt